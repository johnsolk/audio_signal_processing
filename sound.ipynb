{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdcdc2d5-60d2-4c18-8707-ee4beaa5fc9b",
   "metadata": {},
   "source": [
    "# Sound processing with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7770ef-a700-483a-b7e5-37c56a9e3e2e",
   "metadata": {},
   "source": [
    "Input wav files used: https://freesound.org/people/flcellogrl/packs/12408/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4018a-5c63-465e-8406-22299bc4c426",
   "metadata": {},
   "source": [
    "# What are sound data? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0bd710-cfd8-458c-a240-83671378acfc",
   "metadata": {},
   "source": [
    "This notebook explores the following libraries:\n",
    "* scipy importing WAV format\n",
    "* matplotlib for plotting\n",
    "* numpy for matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40439f5b-fce8-4d07-b663-7c654fd824e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6659128-fb0a-4a0d-a470-dce2b6a7690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read in module scipy.io.wavfile:\n",
      "\n",
      "read(filename, mmap=False)\n",
      "    Open a WAV file.\n",
      "    \n",
      "    Return the sample rate (in samples/sec) and data from an LPCM WAV file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filename : string or open file handle\n",
      "        Input WAV file.\n",
      "    mmap : bool, optional\n",
      "        Whether to read data as memory-mapped (default: False).  Not compatible\n",
      "        with some bit depths; see Notes.  Only to be used on real files.\n",
      "    \n",
      "        .. versionadded:: 0.12.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    rate : int\n",
      "        Sample rate of WAV file.\n",
      "    data : numpy array\n",
      "        Data read from WAV file. Data-type is determined from the file;\n",
      "        see Notes.  Data is 1-D for 1-channel WAV, or 2-D of shape\n",
      "        (Nsamples, Nchannels) otherwise. If a file-like input without a\n",
      "        C-like file descriptor (e.g., :class:`python:io.BytesIO`) is\n",
      "        passed, this will not be writeable.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Common data types: [1]_\n",
      "    \n",
      "    =====================  ===========  ===========  =============\n",
      "         WAV format            Min          Max       NumPy dtype\n",
      "    =====================  ===========  ===========  =============\n",
      "    32-bit floating-point  -1.0         +1.0         float32\n",
      "    32-bit integer PCM     -2147483648  +2147483647  int32\n",
      "    24-bit integer PCM     -2147483648  +2147483392  int32\n",
      "    16-bit integer PCM     -32768       +32767       int16\n",
      "    8-bit integer PCM      0            255          uint8\n",
      "    =====================  ===========  ===========  =============\n",
      "    \n",
      "    WAV files can specify arbitrary bit depth, and this function supports\n",
      "    reading any integer PCM depth from 1 to 64 bits.  Data is returned in the\n",
      "    smallest compatible numpy int type, in left-justified format.  8-bit and\n",
      "    lower is unsigned, while 9-bit and higher is signed.\n",
      "    \n",
      "    For example, 24-bit data will be stored as int32, with the MSB of the\n",
      "    24-bit data stored at the MSB of the int32, and typically the least\n",
      "    significant byte is 0x00.  (However, if a file actually contains data past\n",
      "    its specified bit depth, those bits will be read and output, too. [2]_)\n",
      "    \n",
      "    This bit justification and sign matches WAV's native internal format, which\n",
      "    allows memory mapping of WAV files that use 1, 2, 4, or 8 bytes per sample\n",
      "    (so 24-bit files cannot be memory-mapped, but 32-bit can).\n",
      "    \n",
      "    IEEE float PCM in 32- or 64-bit format is supported, with or without mmap.\n",
      "    Values exceeding [-1, +1] are not clipped.\n",
      "    \n",
      "    Non-linear PCM (mu-law, A-law) is not supported.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] IBM Corporation and Microsoft Corporation, \"Multimedia Programming\n",
      "       Interface and Data Specifications 1.0\", section \"Data Format of the\n",
      "       Samples\", August 1991\n",
      "       http://www.tactilemedia.com/info/MCI_Control_Info.html\n",
      "    .. [2] Adobe Systems Incorporated, \"Adobe Audition 3 User Guide\", section\n",
      "       \"Audio file formats: 24-bit Packed Int (type 1, 20-bit)\", 2007\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from os.path import dirname, join as pjoin\n",
      "    >>> from scipy.io import wavfile\n",
      "    >>> import scipy.io\n",
      "    \n",
      "    Get the filename for an example .wav file from the tests/data directory.\n",
      "    \n",
      "    >>> data_dir = pjoin(dirname(scipy.io.__file__), 'tests', 'data')\n",
      "    >>> wav_fname = pjoin(data_dir, 'test-44100Hz-2ch-32bit-float-be.wav')\n",
      "    \n",
      "    Load the .wav file contents.\n",
      "    \n",
      "    >>> samplerate, data = wavfile.read(wav_fname)\n",
      "    >>> print(f\"number of channels = {data.shape[1]}\")\n",
      "    number of channels = 2\n",
      "    >>> length = data.shape[0] / samplerate\n",
      "    >>> print(f\"length = {length}s\")\n",
      "    length = 0.01s\n",
      "    \n",
      "    Plot the waveform.\n",
      "    \n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> import numpy as np\n",
      "    >>> time = np.linspace(0., length, data.shape[0])\n",
      "    >>> plt.plot(time, data[:, 0], label=\"Left channel\")\n",
      "    >>> plt.plot(time, data[:, 1], label=\"Right channel\")\n",
      "    >>> plt.legend()\n",
      "    >>> plt.xlabel(\"Time [s]\")\n",
      "    >>> plt.ylabel(\"Amplitude\")\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f7d412-56fe-4ed6-b9b1-1b740d94648a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/johnsolk/Documents/sound_project/input_files/12408__flcellogrl__real-cello-notes/195272__flcellogrl__1_cello_c2.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Sampling rate and data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m (sample_rate,data)\u001b[38;5;241m=\u001b[39m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/johnsolk/Documents/sound_project/input_files/12408__flcellogrl__real-cello-notes/195272__flcellogrl__1_cello_c2.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m sample_rate\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.jupyter/lib/python3.11/site-packages/scipy/io/wavfile.py:647\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, mmap)\u001b[0m\n\u001b[1;32m    645\u001b[0m     mmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 647\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     file_size, is_big_endian \u001b[38;5;241m=\u001b[39m _read_riff_chunk(fid)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/johnsolk/Documents/sound_project/input_files/12408__flcellogrl__real-cello-notes/195272__flcellogrl__1_cello_c2.wav'"
     ]
    }
   ],
   "source": [
    "# Sampling rate and data\n",
    "(sample_rate,data)=read(\"/Users/johnsolk/Documents/sound_project/input_files/12408__flcellogrl__real-cello-notes/195272__flcellogrl__1_cello_c2.wav\")\n",
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14783e8-68cf-4956-bf3b-5b1704dfadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3f084-2ecb-4902-a162-244262a48245",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"number of channels = {data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ee9d7-c4c0-4306-9ea3-8a8b6937bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45fe6a8-1f96-4c76-ac86-654b02e47c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab3964-afb9-4a63-b91d-74f2259f7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of seconds = size of the array / sampling rate\n",
    "seconds = data.size/sample_rate\n",
    "seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd522a21-1372-4191-a530-5526327c5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc8fe6-8cd9-4fe9-a1b1-ae47245b48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0030c0a3-efcb-46cb-9896-f5dea55ce547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sampling rate to decimal\n",
    "seconds = data.size/float(sample_rate)\n",
    "seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c874d11-1ea6-4827-9daf-fe00bd970eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt(data,label=\"channels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c8d03-e3bb-4799-a561-fcabb4e96f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
